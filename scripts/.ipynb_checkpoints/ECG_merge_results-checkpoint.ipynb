{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ECG_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results for the target Age are: \n",
      "0   model_type n_layers n_nodes optimizer learning_rate resize_factor  \\\n",
      "148     Conv1D        9      32   RMSprop         0.001            12   \n",
      "283  SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "412  SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "3    SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "317  SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "449  SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "422  SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "336  SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "334  SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "226  SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "249  SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "105  SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "4    SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "6    SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "402  SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "403  SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "265     Conv1D        5      64   RMSprop         1e-06            10   \n",
      "72      Conv1D        5      64   RMSprop         1e-06            10   \n",
      "94      Conv1D        5      64   RMSprop         1e-06            10   \n",
      "342     Conv1D        5      64   RMSprop         1e-06            10   \n",
      "65      Conv1D        5      64   RMSprop         1e-06            10   \n",
      "357     Conv1D        5      64   RMSprop         1e-06            10   \n",
      "377     Conv1D        5      64   RMSprop         1e-06            10   \n",
      "45      Conv1D        5      64   RMSprop         1e-06            10   \n",
      "270     Conv1D        5      64   RMSprop         1e-06            10   \n",
      "59      Conv1D        5      64   RMSprop         1e-06            10   \n",
      "367     Conv1D        5      64   RMSprop         1e-06            10   \n",
      "225     Conv1D        5      64   RMSprop         1e-06            10   \n",
      "345  SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "286     Conv1D        5      64   RMSprop         1e-06            10   \n",
      "..         ...      ...     ...       ...           ...           ...   \n",
      "52      Conv1D        5       4  Adadelta         1e-05             1   \n",
      "262     Conv1D        5       4  Adadelta         1e-05             1   \n",
      "427     Conv1D        5       4  Adadelta         1e-05             1   \n",
      "145     Conv1D        5       4  Adadelta         1e-05             1   \n",
      "448     Conv1D        5       4  Adadelta         1e-05             1   \n",
      "293        GRU        2    1024  Adadelta         1e-05             4   \n",
      "415     Conv1D        5       4  Adadelta         1e-05             1   \n",
      "259        GRU        6      32  Adadelta         1e-06            12   \n",
      "106        GRU        6      32  Adadelta         1e-06            12   \n",
      "264     Conv1D        5       4  Adadelta         1e-05             1   \n",
      "241        GRU        6      32  Adadelta         1e-06            12   \n",
      "272     Conv1D        5       4  Adadelta         1e-05             1   \n",
      "292        GRU        6      32  Adadelta         1e-06            12   \n",
      "44         GRU        6      32  Adadelta         1e-06            12   \n",
      "327     Conv1D        5       4  Adadelta         1e-05             1   \n",
      "61         GRU        6      32  Adadelta         1e-06            12   \n",
      "454     Conv1D        5       4  Adadelta         1e-05             1   \n",
      "255        GRU        6      32  Adadelta         1e-06            12   \n",
      "213        GRU        6      32  Adadelta         1e-06            12   \n",
      "113     Conv1D        5       4  Adadelta         1e-05             1   \n",
      "423        GRU        6      32  Adadelta         1e-06            12   \n",
      "339     Conv1D        5    1024      Adam           0.1            25   \n",
      "164     Conv1D        5    1024      Adam           0.1            25   \n",
      "414        GRU        5     512      Adam           0.1            25   \n",
      "133     Conv1D        5    1024      Adam           0.1            25   \n",
      "408     Conv1D        5    1024      Adam           0.1            25   \n",
      "426     Conv1D        5    1024      Adam           0.1            25   \n",
      "206     Conv1D        5    1024      Adam           0.1            25   \n",
      "92      Conv1D        5    1024      Adam           0.1            25   \n",
      "347     Conv1D        5    1024      Adam           0.1            25   \n",
      "\n",
      "0   batch_size n_epochs_run Performance_train Performance_val Performance_test  \n",
      "148       1024          100          0.300584        0.227876         0.238784  \n",
      "283       1024         1900          0.239634        0.224556         0.191653  \n",
      "412       1024         2100          0.244382         0.22381         0.192962  \n",
      "3         1024         1800          0.240019         0.22373          0.19197  \n",
      "317       1024         2000          0.241971        0.222074         0.191371  \n",
      "449       1024         1600          0.235743        0.221315         0.188841  \n",
      "422       1024         1400          0.231121        0.219777         0.186834  \n",
      "336       1024         1700          0.236221        0.219744         0.188749  \n",
      "334       1024         1500          0.232967        0.219015         0.187281  \n",
      "226       1024         1300          0.228635        0.218234         0.185111  \n",
      "249       1024         1100          0.223191        0.214268          0.18143  \n",
      "105       1024         1000          0.218063        0.211795         0.176953  \n",
      "4         1024          900          0.216335        0.210825         0.176476  \n",
      "6         1024          800          0.212502        0.208263         0.175045  \n",
      "402       1024          700          0.207819        0.205662         0.171625  \n",
      "403       1024         1200          0.217849        0.204787         0.173717  \n",
      "265       1024         9500           0.22799        0.204515         0.217209  \n",
      "72        1024         9700          0.229035         0.20442         0.217472  \n",
      "94        1024         9600          0.228519        0.204172         0.217244  \n",
      "342       1024         9300          0.227022        0.203819         0.216662  \n",
      "65        1024         9400          0.227502        0.203727         0.216757  \n",
      "357       1024         9200          0.226508        0.203563         0.216414  \n",
      "377       1024         9100          0.225993        0.203267         0.216166  \n",
      "45        1024         9000          0.225463        0.203168         0.215981  \n",
      "270       1024         8900          0.224957        0.202762         0.215691  \n",
      "59        1024         8800          0.224432        0.202536         0.215461  \n",
      "367       1024         8600          0.223324        0.202227         0.214999  \n",
      "225       1024         8700          0.223903        0.202206         0.215165  \n",
      "345       1024          600          0.202466        0.202037         0.169907  \n",
      "286       1024         8500          0.222825        0.201863         0.214716  \n",
      "..         ...          ...               ...             ...              ...  \n",
      "52        1024         1100          -3.85292        -3.83744         -3.99144  \n",
      "262       1024         1000          -3.86432        -3.84888         -4.00323  \n",
      "427       1024          900          -3.87587        -3.86046         -4.01523  \n",
      "145       1024          800          -3.88771        -3.87237         -4.02754  \n",
      "448       1024          700          -3.90001         -3.8847         -4.04032  \n",
      "293       1024          100           -3.9048        -3.88943         -4.04421  \n",
      "415       1024          600           -3.9128        -3.89752         -4.05361  \n",
      "259       1024          900          -3.91352        -3.89814         -4.05354  \n",
      "106       1024          800           -3.9235        -3.90809         -4.06384  \n",
      "264       1024          500          -3.92598        -3.91058         -4.06734  \n",
      "241       1024          700          -3.93292        -3.91747         -4.07356  \n",
      "272       1024          400          -3.93915        -3.92367         -4.08105  \n",
      "292       1024          600          -3.94174        -3.92625         -4.08266  \n",
      "44        1024          500          -3.94989        -3.93438         -4.09108  \n",
      "327       1024          300          -3.95182        -3.93629         -4.09418  \n",
      "61        1024          400          -3.95732        -3.94178         -4.09875  \n",
      "454       1024          200          -3.96333        -3.94775         -4.10606  \n",
      "255       1024          300          -3.96393        -3.94837         -4.10557  \n",
      "213       1024          200          -3.96959          -3.954         -4.11141  \n",
      "113       1024          100          -3.97272        -3.95706         -4.11574  \n",
      "423       1024          100          -3.97408        -3.95847         -4.11604  \n",
      "339       1024          800           -5.7833        -5.76092         -5.98271  \n",
      "164       1024          700          -10.8727        -10.8315         -11.2305  \n",
      "414       1024          500          -11.6269        -11.5829         -12.0079  \n",
      "133       1024          600          -13.2745        -13.2244         -13.7059  \n",
      "408       1024          500          -14.1397        -14.0864         -14.5975  \n",
      "426       1024          400           -14.425        -14.3707         -14.8916  \n",
      "206       1024          300          -14.5165        -14.4618         -14.9858  \n",
      "92        1024          200          -14.5455        -14.4907         -15.0157  \n",
      "347       1024          100          -14.5545        -14.4997         -15.0251  \n",
      "\n",
      "[475 rows x 11 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results for the target Sex are: \n",
      "0   model_type n_layers n_nodes optimizer learning_rate resize_factor  \\\n",
      "75   SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "18   SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "40   SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "7    SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "59   SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "68   SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "24   SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "61   SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "33   SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "95   SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "80   SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "92   SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "52   SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "53   SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "43   SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "32   SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "10   SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "17   SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "85   SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "79   SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "101  SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "45   SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "37   SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "74   SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "70   SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "82   SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "63   SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "46   SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "83   SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "30   SimpleRNN        6      32   RMSprop         1e-05            25   \n",
      "..         ...      ...     ...       ...           ...           ...   \n",
      "28   SimpleRNN        3       4  Adadelta         1e-06             3   \n",
      "36   SimpleRNN        3       4  Adadelta         1e-06             3   \n",
      "20   SimpleRNN        3       4  Adadelta         1e-06             3   \n",
      "29   SimpleRNN        3       4  Adadelta         1e-06             3   \n",
      "19   SimpleRNN        3       4  Adadelta         1e-06             3   \n",
      "16   SimpleRNN        9      64      Adam           0.1             6   \n",
      "15   SimpleRNN        9      64      Adam           0.1             6   \n",
      "67   SimpleRNN        9      64      Adam           0.1             6   \n",
      "66   SimpleRNN        9      64      Adam           0.1             6   \n",
      "94         GRU        9       4      Adam           0.1            40   \n",
      "88   SimpleRNN        9      64      Adam           0.1             6   \n",
      "89        LSTM        3      64   RMSprop          0.01             3   \n",
      "0         LSTM        3      64   RMSprop          0.01             3   \n",
      "44        LSTM        3      64   RMSprop          0.01             3   \n",
      "69         GRU        9       4      Adam           0.1            40   \n",
      "49         GRU        9       4      Adam           0.1            40   \n",
      "77         GRU        9       4      Adam           0.1            40   \n",
      "38         GRU        9       4      Adam           0.1            40   \n",
      "22   SimpleRNN        9      64      Adam           0.1             6   \n",
      "12         GRU        9       4      Adam           0.1            40   \n",
      "23        LSTM        5       8  Adadelta         0.001             5   \n",
      "76        LSTM        5       8  Adadelta         0.001             5   \n",
      "54        LSTM        5       8  Adadelta         0.001             5   \n",
      "65         GRU        6      32  Adadelta         1e-06            12   \n",
      "98         GRU        6      32  Adadelta         1e-06            12   \n",
      "6          GRU        6      32  Adadelta         1e-06            12   \n",
      "51         GRU        6      32  Adadelta         1e-06            12   \n",
      "62         GRU        6      32  Adadelta         1e-06            12   \n",
      "8          GRU        6      32  Adadelta         1e-06            12   \n",
      "84         GRU        6      32  Adadelta         1e-06            12   \n",
      "\n",
      "0   batch_size n_epochs_run Performance_train Performance_val Performance_test  \n",
      "75        1024         2900          0.954894        0.939631         0.934139  \n",
      "18        1024         2700          0.953615        0.939551         0.934071  \n",
      "40        1024         3100          0.956051        0.939454         0.934533  \n",
      "7         1024         3000          0.955504        0.939442         0.934097  \n",
      "59        1024         2800          0.954136        0.939091         0.934298  \n",
      "68        1024         2400          0.951674        0.939017         0.934183  \n",
      "24        1024         2600          0.952997        0.938989         0.934056  \n",
      "61        1024         2300          0.950934        0.938832         0.933954  \n",
      "33        1024         2500           0.95235        0.938823         0.933988  \n",
      "95        1024         2200          0.950194        0.938796         0.933643  \n",
      "80        1024         2100          0.949409        0.938627         0.933582  \n",
      "92        1024         2000          0.948491        0.938432         0.933439  \n",
      "52        1024         1900          0.947753        0.938281         0.933057  \n",
      "53        1024         1800           0.94685        0.937946         0.932828  \n",
      "43        1024         1700          0.945941        0.937681         0.932308  \n",
      "32        1024         1600          0.944981        0.937673         0.931927  \n",
      "10        1024         1500          0.943953        0.937133         0.931741  \n",
      "17        1024         1400          0.942936        0.936732         0.931118  \n",
      "85        1024         1300          0.941661         0.93594         0.930313  \n",
      "79        1024         1200          0.940539         0.93582         0.929832  \n",
      "101       1024         1100          0.939185        0.935239         0.929279  \n",
      "45        1024         1000          0.937765        0.934323         0.928516  \n",
      "37        1024          900           0.93617        0.933343         0.927674  \n",
      "74        1024          800          0.934407        0.932232         0.926575  \n",
      "70        1024          700          0.932453        0.930927         0.925305  \n",
      "82        1024          600          0.930252        0.929007         0.923845  \n",
      "63        1024          500          0.927892        0.927474         0.922302  \n",
      "46        1024          400          0.924928        0.925187         0.919716  \n",
      "83        1024          300          0.921068        0.922365         0.916263  \n",
      "30        1024          200          0.914884        0.917005         0.909399  \n",
      "..         ...          ...               ...             ...              ...  \n",
      "28        1024          500          0.598666        0.595579           0.5894  \n",
      "36        1024          400          0.598659         0.59555         0.589394  \n",
      "20        1024          300           0.59865        0.595532         0.589357  \n",
      "29        1024          200          0.598644        0.595504         0.589359  \n",
      "19        1024          100          0.598636        0.595463         0.589359  \n",
      "16        1024          400          0.507069        0.509725         0.492728  \n",
      "15        1024          200          0.505697        0.507085         0.491409  \n",
      "67        1024          100          0.504911         0.50326          0.48989  \n",
      "66        1024          300           0.50616        0.502189         0.494118  \n",
      "94        1024          600          0.499868             0.5              0.5  \n",
      "88        1024          600          0.499868             0.5              0.5  \n",
      "89        1024          200          0.499868             0.5              0.5  \n",
      "0         1024          300               0.5             0.5              0.5  \n",
      "44        1024          100          0.499868             0.5              0.5  \n",
      "69        1024          100               0.5             0.5              0.5  \n",
      "49        1024          300               0.5             0.5              0.5  \n",
      "77        1024          500               0.5             0.5              0.5  \n",
      "38        1024          400               0.5             0.5              0.5  \n",
      "22        1024          500          0.500132             0.5              0.5  \n",
      "12        1024          200               0.5             0.5              0.5  \n",
      "23        1024          300          0.475423        0.482912         0.481891  \n",
      "76        1024          200           0.47523        0.482844         0.481749  \n",
      "54        1024          100           0.47504        0.482826         0.481593  \n",
      "65        1024          200          0.354897         0.35489         0.362219  \n",
      "98        1024          500          0.354896         0.35489          0.36222  \n",
      "6         1024          600          0.354895        0.354888         0.362224  \n",
      "51        1024          400          0.354895        0.354888         0.362222  \n",
      "62        1024          700          0.354896        0.354883         0.362227  \n",
      "8         1024          100          0.354897        0.354882         0.362213  \n",
      "84        1024          300          0.354896        0.354882         0.362229  \n",
      "\n",
      "[102 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "#find all files in the results folder, then concatenate all the dictionaries into a panda dataframe\n",
    "for target in targets:\n",
    "    df = pd.DataFrame()\n",
    "    for file in [file for file in os.listdir(path_store + 'performances_and_hyperparameters') if file.startswith('performances_and_hyperparameters_' + target)]:\n",
    "        if df.empty: #initiate the dataframe\n",
    "            df = pd.DataFrame(list(json.load(open(path_store + 'performances_and_hyperparameters/' + file)).items())).transpose()\n",
    "            df.columns = df.iloc[0]\n",
    "            df = df.reindex(df.index.drop(0))\n",
    "            df = df[['model_type', 'n_layers', 'n_nodes', 'optimizer', 'learning_rate', 'resize_factor', 'batch_size', 'n_epochs_run', 'Performance_train', 'Performance_val', 'Performance_test']]\n",
    "        else:\n",
    "            df = df.append(json.load(open(path_store + 'performances_and_hyperparameters/' + file)), ignore_index=True)\n",
    "    df=df.sort_values(by='Performance_val', ascending=False)\n",
    "    df.to_csv(path_store + 'results_' + target + '.csv')\n",
    "    print('The results for the target ' + target + ' are: ')\n",
    "    print(df)\n",
    "    globals()['results_' + target] = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
